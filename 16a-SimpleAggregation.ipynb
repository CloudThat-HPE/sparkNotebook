{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa42050",
   "metadata": {},
   "source": [
    "# Aggregation\n",
    "Three Types\n",
    "## Simple - avg, count, min, max, sum\n",
    "## Grouping - same as simple\n",
    "## Windowing - lead lag rank dense_rank cust_dist\n",
    "All aggregaions in spark implemented using built in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a18fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "            .master(\"local[3]\") \\\n",
    "            .appName(\"Misc Transformations\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e2e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_df = spark.read \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .load(\"data/invoices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a87c4470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----------------+-------------+\n",
      "|Count *|TotalQuantity|         AvgPrice|CountDistinct|\n",
      "+-------+-------------+-----------------+-------------+\n",
      "| 541909|      5176450|4.611113626088512|        25900|\n",
      "+-------+-------------+-----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Column Object Expression\n",
    "invoice_df.select(f.count(\"*\").alias(\"Count *\"),\n",
    "                      f.sum(\"Quantity\").alias(\"TotalQuantity\"),\n",
    "                      f.avg(\"UnitPrice\").alias(\"AvgPrice\"),\n",
    "                      f.countDistinct(\"InvoiceNo\").alias(\"CountDistinct\") #count distinct invoices\n",
    "                      ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18662cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------+-----------------+\n",
      "|count 1|count field|TotalQuantity|         AvgPrice|\n",
      "+-------+-----------+-------------+-----------------+\n",
      "| 541909|     541908|      5176450|4.611113626086851|\n",
      "+-------+-----------+-------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#as sql expressions\n",
    "invoice_df.selectExpr(\n",
    "    \"count(1) as `count 1`\",              #count all including null\n",
    "    \"count(StockCode) as `count field`\",  #count aviding null value in field\n",
    "    \"sum(Quantity) as TotalQuantity\",\n",
    "    \"avg(UnitPrice) as AvgPrice\"\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d802e174",
   "metadata": {},
   "source": [
    "Now we want summaise records all about country invoiveno qantity invoicevalue (invoice value to be calculated as qauntity multiply by unit price)\n",
    "also group result by country\n",
    "\n",
    "select country, InvoiceNo, sum(quantity) as TotalQuantity, round(quantity X unitprice,2) as invoicePice from tabl groupby country, Invoice no \n",
    "\n",
    "this is sql query. use it in spark sql. for that you need to create table from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02914002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-------------+------------+\n",
      "|       Country|InvoiceNo|TotalQuantity|InvoiceValue|\n",
      "+--------------+---------+-------------+------------+\n",
      "|United Kingdom|   536446|          329|      440.89|\n",
      "|United Kingdom|   536508|          216|      155.52|\n",
      "|United Kingdom|   537018|           -3|         0.0|\n",
      "|United Kingdom|   537401|          -24|         0.0|\n",
      "|United Kingdom|   537811|           74|      268.86|\n",
      "|United Kingdom|  C537824|           -2|       -14.9|\n",
      "|United Kingdom|   538895|          370|      247.38|\n",
      "|United Kingdom|   540453|          341|      302.45|\n",
      "|United Kingdom|   541291|          217|      305.81|\n",
      "|United Kingdom|   542551|           -1|         0.0|\n",
      "|United Kingdom|   542576|           -1|         0.0|\n",
      "|United Kingdom|   542628|            9|      132.35|\n",
      "|United Kingdom|   542886|          199|      320.51|\n",
      "|United Kingdom|   542907|           75|      313.85|\n",
      "|United Kingdom|   543131|          134|       164.1|\n",
      "|United Kingdom|   543189|          102|      153.94|\n",
      "|United Kingdom|   543265|           -4|         0.0|\n",
      "|        Cyprus|   544574|          173|      320.69|\n",
      "|United Kingdom|   545077|           24|       10.08|\n",
      "|United Kingdom|   545300|          116|      323.16|\n",
      "+--------------+---------+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "invoice_df.createOrReplaceTempView(\"sales\")\n",
    "summary_sql = spark.sql(\"\"\"\n",
    "        SELECT Country, InvoiceNo,\n",
    "            sum(Quantity) as TotalQuantity,\n",
    "            round(sum(Quantity*UnitPrice),2) as InvoiceValue\n",
    "        FROM sales\n",
    "        GROUP BY Country, InvoiceNo\"\"\")\n",
    "\n",
    "summary_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca5ffb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-------------+------------+----------------+\n",
      "|       Country|InvoiceNo|TotalQuantity|InvoiceValue|InvoiceValueExpr|\n",
      "+--------------+---------+-------------+------------+----------------+\n",
      "|United Kingdom|   536446|          329|      440.89|          440.89|\n",
      "|United Kingdom|   536508|          216|      155.52|          155.52|\n",
      "|United Kingdom|   537018|           -3|         0.0|             0.0|\n",
      "|United Kingdom|   537401|          -24|         0.0|             0.0|\n",
      "|United Kingdom|   537811|           74|      268.86|          268.86|\n",
      "|United Kingdom|  C537824|           -2|       -14.9|           -14.9|\n",
      "|United Kingdom|   538895|          370|      247.38|          247.38|\n",
      "|United Kingdom|   540453|          341|      302.45|          302.45|\n",
      "|United Kingdom|   541291|          217|      305.81|          305.81|\n",
      "|United Kingdom|   542551|           -1|         0.0|             0.0|\n",
      "|United Kingdom|   542576|           -1|         0.0|             0.0|\n",
      "|United Kingdom|   542628|            9|      132.35|          132.35|\n",
      "|United Kingdom|   542886|          199|      320.51|          320.51|\n",
      "|United Kingdom|   542907|           75|      313.85|          313.85|\n",
      "|United Kingdom|   543131|          134|       164.1|           164.1|\n",
      "|United Kingdom|   543189|          102|      153.94|          153.94|\n",
      "|United Kingdom|   543265|           -4|         0.0|             0.0|\n",
      "|        Cyprus|   544574|          173|      320.69|          320.69|\n",
      "|United Kingdom|   545077|           24|       10.08|           10.08|\n",
      "|United Kingdom|   545300|          116|      323.16|          323.16|\n",
      "+--------------+---------+-------------+------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# you can do same using dataframe expressio also\n",
    "summary_df = invoice_df \\\n",
    "        .groupBy(\"Country\", \"InvoiceNo\") \\\n",
    "        .agg(f.sum(\"Quantity\").alias(\"TotalQuantity\"),\n",
    "             f.round(f.sum(f.expr(\"Quantity * UnitPrice\")), 2).alias(\"InvoiceValue\"),\n",
    "             f.expr(\"round(sum(Quantity * UnitPrice),2) as InvoiceValueExpr\")\n",
    "             )\n",
    "\n",
    "summary_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987d4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
