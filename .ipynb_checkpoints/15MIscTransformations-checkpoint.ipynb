{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea5a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "            .master(\"local[3]\") \\\n",
    "            .appName(\"Misc Transformations\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "data_list = [(\"Ravi\", \"28\", \"1\", \"2002\"),\n",
    "             (\"Abdul\", \"23\", \"5\", \"81\"),\n",
    "             (\"John\", \"12\", \"12\", \"6\"),\n",
    "             (\"Rosy\", \"7\", \"8\", \"63\"),\n",
    "             (\"Abdul\", \"23\", \"5\", \"81\")\n",
    "            ]\n",
    "\n",
    "data_list1 = [(\"Ravi\", 28, 1, 2002),\n",
    "             (\"Abdul\", 23, 5, 81),\n",
    "             (\"John\", 12, 12, 6),\n",
    "             (\"Rosy\", 7, 8, 63),\n",
    "             (\"Abdul\", 23, 5, 81)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc1ae9",
   "metadata": {},
   "source": [
    "1. Quick method to create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb52119",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = spark.createDataFrame(data_list)\n",
    "raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a279ac34",
   "metadata": {},
   "source": [
    "However we infered schema automatically. so might incorrect for some columns. as well as we dont have meaningful column names. and we do have duplicate entries as well.\n",
    "\n",
    "so how to get schema for dataframe namedtuple right. so define it and attach schema.\n",
    "\n",
    "however we have quick method to do it use toDF method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = spark.createDataFrame(data_list).toDF(\"name\", \"day\", \"month\", \"year\")\n",
    "raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9bb1f5",
   "metadata": {},
   "source": [
    "2. How to add column with monotonically increasing id\n",
    "withColumn can allow to create column as well. monotonically_increasing_id generates unique integer for every record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42491d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = raw_df.withColumn(\"id\", monotonically_increasing_id())\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42844007",
   "metadata": {},
   "source": [
    "3. How to use use case when Then\n",
    "these are popular constructs in programming language\n",
    "will use to avoid lengthy if else statements\n",
    "lets use it to fix year digit problem. we have two digit year make it four digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf53d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.withColumn(\"year\", expr(\"\"\"\n",
    "         case when year < 21 then year + 2000\n",
    "         when year < 100 then year + 1900\n",
    "         else year\n",
    "         end\"\"\"))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6378183c",
   "metadata": {},
   "source": [
    "noe year in decimal. cause datatye is in string and we are performing arithmetic operation so promoted to decimal and then again after demoted to string.\n",
    "\n",
    "How to fix it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed47ac",
   "metadata": {},
   "source": [
    "3. How to cast your fields\n",
    "two methods\n",
    "inline cast: doesnot allow spark to promote and demote field automatically;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf982608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1.withColumn(\"year\", expr(\"\"\"\n",
    "         case when year < 21 then cast(year as int) + 2000\n",
    "         when year < 100 then cast(year as int) + 1900\n",
    "         else year\n",
    "         end\"\"\"))\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522ce243",
   "metadata": {},
   "source": [
    "Change Schema Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df1.withColumn(\"year\", expr(\"\"\"\n",
    "         case when year < 21 then year + 2000\n",
    "         when year < 100 then year + 1900\n",
    "         else year\n",
    "         end\"\"\").cast(IntegerType()))\n",
    "df4.show()\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22151bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.show()\n",
    "df1.printSchema()\n",
    "\n",
    "df5 = df1.withColumn(\"day\", col(\"day\").cast(IntegerType())) \\\n",
    "         .withColumn(\"month\", col(\"month\").cast(IntegerType())) \\\n",
    "         .withColumn(\"year\", col(\"year\").cast(IntegerType())) \n",
    "\n",
    "df5.printSchema()\n",
    "\n",
    "df6 = df5.withColumn(\"year\", expr(\"\"\"\n",
    "         case when year < 21 then year + 2000\n",
    "         when year < 100 then year + 1900\n",
    "         else year\n",
    "         end\"\"\"))\n",
    "df6.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
