{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b6cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0759ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "437876ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.logger import Log4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130dd675",
   "metadata": {},
   "source": [
    "Setting up configuration appname and master from code (HardCoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b68fef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Hello Spark\").master(\"local[3]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d89297fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Log4j(spark)\n",
    "logger.info(\"Starting HelloSpark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e50039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "| age|    name|\n",
      "+----+--------+\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.json(\"data/people.json\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58b6341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Finished HelloSpark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c3596ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3db3c",
   "metadata": {},
   "source": [
    "# Setting up SparkConf Object-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7436f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init() \n",
    "import pyspark\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f881dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.logger import Log4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d35f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f9593",
   "metadata": {},
   "source": [
    "use conf.set() method to set as many cogigurations as you want but you must know spark congiguration property name https://spark.apache.org/docs/2.3.0/configuration.html#available-properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6155ed10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x213ed051cd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf.set(\"spark.app.name\",\"Hello Spark\")\n",
    "conf.set(\"spark.master\",\"local[3]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e38d2675",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b115b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "| age|    name|\n",
      "+----+--------+\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger = Log4j(spark)\n",
    "logger.info(\"Starting HelloSpark\")\n",
    "spark.read.json(\"data/people.json\").show()\n",
    "logger.info(\"Finished HelloSpark\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84793e6",
   "metadata": {},
   "source": [
    "# Setting up SparkConf Object-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c8bb40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init() \n",
    "import pyspark\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e01836c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.logger import Log4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd58fd8",
   "metadata": {},
   "source": [
    "create new file spark.conf and put sparkcongiguration properties in this file to load at runtime.\n",
    "Create python file utils.py and and following lines \n",
    "import configparser\n",
    "\n",
    "from pyspark import SparkConf\n",
    "\n",
    "def get_spark_app_config():\n",
    "    spark_conf = SparkConf()\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(\"spark.conf\")\n",
    "\n",
    "    for (key, val) in config.items(\"SPARK_APP_CONFIGS\"):\n",
    "        spark_conf.set(key, val)\n",
    "    return spark_conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21b0f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.utils import get_spark_app_config\n",
    "conf = get_spark_app_config()\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "655d491b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "| age|    name|\n",
      "+----+--------+\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "|null|Prashant|\n",
      "|  30|   Abdul|\n",
      "|  19|  Justin|\n",
      "|  43|    Andy|\n",
      "+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logger = Log4j(spark)\n",
    "logger.info(\"Starting HelloSpark\")\n",
    "spark.read.json(\"data/people.json\").show()\n",
    "conf_out = spark.sparkContext.getConf()\n",
    "logger.info(conf_out.toDebugString())\n",
    "logger.info(\"Finished HelloSpark\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd991fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
