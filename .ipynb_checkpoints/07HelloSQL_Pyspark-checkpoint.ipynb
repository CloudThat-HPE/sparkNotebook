{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e35b73",
   "metadata": {},
   "source": [
    "# SQL API inside PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7130384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from lib.logger import Log4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8dbeae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[3]\").appName(\"Hello SQL\").getOrCreate()\n",
    "logger = Log4j(spark)\n",
    "logger.info(\"Starting HelloSparkSQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18f49509",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyDF = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .csv(\"data/sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0887e7e0",
   "metadata": {},
   "source": [
    "We already learnt to use dataframe Reader API and Transformations & action to make changes in dataframe. also we learn alternatives using rdd.\n",
    "Now we can perform same using spark sql expression.\n",
    "\n",
    "We can execute sql expression only on spark table or view.\n",
    "\n",
    "Spark allow you to register your dataframe as View."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117ad4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|       Country|count|\n",
      "+--------------+-----+\n",
      "| United States|    4|\n",
      "|        Canada|    2|\n",
      "|United Kingdom|    1|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "surveyDF.createOrReplaceTempView(\"survey_tbl\")\n",
    "\n",
    "countDF = spark.sql(\"select Country, count(1) as count from survey_tbl where Age<40 group by Country\")\n",
    "\n",
    "countDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27b796a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
