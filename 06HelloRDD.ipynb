{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad323df4",
   "metadata": {},
   "source": [
    "To use RDD API you need spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f51b5743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from lib.logger import Log4j\n",
    "from lib.utils import get_spark_app_config,load_survey_df,count_by_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d5e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf() \\\n",
    "        .setMaster(\"local[3]\") \\\n",
    "        .setAppName(\"HelloRDD\")\n",
    "#conf = get_spark_app_config()\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "logger = Log4j(spark)\n",
    "logger.info(\"Starting HelloSpark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fbdfd5",
   "metadata": {},
   "source": [
    "Create RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c7e7612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2014-08-27 11:29:31,37,\"Female\",\"United States\",\"IL\",NA,\"No\",\"Yes\",\"Often\",\"6-25\",\"No\",\"Yes\",\"Yes\",\"Not sure\",\"No\",\"Yes\",\"Yes\",\"Somewhat easy\",\"No\",\"No\",\"Some of them\",\"Yes\",\"No\",\"Maybe\",\"Yes\",\"No\",NA',\n",
       " '2014-08-27 11:29:37,44,\"M\",\"United States\",\"IN\",NA,\"No\",\"No\",\"Rarely\",\"More than 1000\",\"No\",\"No\",\"Don\\'t know\",\"No\",\"Don\\'t know\",\"Don\\'t know\",\"Don\\'t know\",\"Don\\'t know\",\"Maybe\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Don\\'t know\",\"No\",NA',\n",
       " '2014-08-27 11:29:44,32,\"Male\",\"Canada\",NA,NA,\"No\",\"No\",\"Rarely\",\"6-25\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"Don\\'t know\",\"Somewhat difficult\",\"No\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",NA',\n",
       " '2014-08-27 11:29:46,31,\"Male\",\"United Kingdom\",NA,NA,\"Yes\",\"Yes\",\"Often\",\"26-100\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Somewhat difficult\",\"Yes\",\"Yes\",\"Some of them\",\"No\",\"Maybe\",\"Maybe\",\"No\",\"Yes\",NA',\n",
       " '2014-08-27 11:30:22,31,\"Male\",\"United States\",\"TX\",NA,\"No\",\"No\",\"Never\",\"100-500\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"Don\\'t know\",\"Don\\'t know\",\"Don\\'t know\",\"Don\\'t know\",\"No\",\"No\",\"Some of them\",\"Yes\",\"Yes\",\"Yes\",\"Don\\'t know\",\"No\",NA',\n",
       " '2014-08-27 11:31:22,33,\"Male\",\"United States\",\"TN\",NA,\"Yes\",\"No\",\"Sometimes\",\"6-25\",\"No\",\"Yes\",\"Yes\",\"Not sure\",\"No\",\"Don\\'t know\",\"Don\\'t know\",\"Don\\'t know\",\"No\",\"No\",\"Yes\",\"Yes\",\"No\",\"Maybe\",\"Don\\'t know\",\"No\",NA',\n",
       " '2014-08-27 11:31:50,35,\"Female\",\"United States\",\"MI\",NA,\"Yes\",\"Yes\",\"Sometimes\",\"1-5\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"No\",\"No\",\"Somewhat difficult\",\"Maybe\",\"Maybe\",\"Some of them\",\"No\",\"No\",\"No\",\"Don\\'t know\",\"No\",NA',\n",
       " '2014-08-27 11:32:05,39,\"M\",\"Canada\",NA,NA,\"No\",\"No\",\"Never\",\"1-5\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"Don\\'t know\",\"No\",\"No\",\"No\",\"No\",\"No\",\"No\",\"No\",\"No\",NA',\n",
       " '2014-08-27 11:32:39,42,\"Female\",\"United States\",\"IL\",NA,\"Yes\",\"Yes\",\"Sometimes\",\"100-500\",\"No\",\"Yes\",\"Yes\",\"Yes\",\"No\",\"No\",\"No\",\"Very difficult\",\"Maybe\",\"No\",\"Yes\",\"Yes\",\"No\",\"Maybe\",\"No\",\"No\",NA']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linesrdd = sc.textFile(\"data/samplerdd.csv\")\n",
    "linesrdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe8e8f8",
   "metadata": {},
   "source": [
    "How to process RDD?\n",
    "record in rdd are line of text - we dont have schema or row column structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9eb13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitionedrdd = linesrdd.repartition(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f379886",
   "metadata": {},
   "source": [
    "Lets give structure to our records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bdfd3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "colsRDD = partitionedrdd.map(lambda line: line.replace('\"','').split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1dc886",
   "metadata": {},
   "source": [
    "will take map transformation. map function takes the lambda function and call it in loop for each line.\n",
    "with replace we are removing double qoutes and we are splitting line using comma\n",
    "and output is list of (strings)text.\n",
    "Now we have columns but we need schema as well. how to get datatype for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27d9bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "SurveyRecord = namedtuple(\"SurveyRecord\", [\"Age\", \"Gender\", \"Country\", \"State\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4672093e",
   "metadata": {},
   "source": [
    "will use surveyrecord named tuple to give schema to our rdd.\n",
    "lets process the colsRDD.\n",
    "use map method to process each row. use survey record object taking into only four rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e51f20ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SurveyRecord(Age=37, Gender='Female', Country='United States', State='IL'), SurveyRecord(Age=44, Gender='M', Country='United States', State='IN'), SurveyRecord(Age=32, Gender='Male', Country='Canada', State='NA'), SurveyRecord(Age=31, Gender='Male', Country='United Kingdom', State='NA'), SurveyRecord(Age=31, Gender='Male', Country='United States', State='TX'), SurveyRecord(Age=33, Gender='Male', Country='United States', State='TN'), SurveyRecord(Age=35, Gender='Female', Country='United States', State='MI'), SurveyRecord(Age=39, Gender='M', Country='Canada', State='NA'), SurveyRecord(Age=42, Gender='Female', Country='United States', State='IL')]\n"
     ]
    }
   ],
   "source": [
    "selectRDD = colsRDD.map(lambda cols: SurveyRecord(int(cols[1]), cols[2], cols[3], cols[4]))\n",
    "print(selectRDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d0edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredRDD = selectRDD.filter(lambda r: r.Age < 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec8092a",
   "metadata": {},
   "source": [
    "Now we want this record grouped by country and count it.\n",
    "for this, first step is to create key value pair. country becomes key and value becomes hardcoded 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90436792",
   "metadata": {},
   "outputs": [],
   "source": [
    "kvRDD = filteredRDD.map(lambda r: (r.Country, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69aa674",
   "metadata": {},
   "source": [
    "Now we get key value rdd. next step is, use reducedByKey method and sum up the hardcoded value 1. that is the count.\n",
    "then collect the count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a216186",
   "metadata": {},
   "outputs": [],
   "source": [
    "countRDD = kvRDD.reduceByKey(lambda v1, v2: v1 + v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328587d2",
   "metadata": {},
   "source": [
    "Get the count and push it to log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7684c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colsList = countRDD.collect()\n",
    "for x in colsList:\n",
    "    logger.info(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ff5e532",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb997823",
   "metadata": {},
   "source": [
    "However GroupBy implementation on RDD is not so obvious and might not make sense at first.\n",
    "That was the challege we face during use of rdd. we need to handcode everything such as grouping and aggregating.\n",
    "Spark Engine had no clue about data strcture inside the rdd, neither spark will look inside your lambda functions and these two things limit spark for creating optimised execution plan.\n",
    "\n",
    "we are not getting into it further as they are raw and outdated API for spark developers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
